## Welcome to The Second Summer School on Statistical Methods for Linguistics and Psychology, 2018, 10-14 September

## Summer School Location

[Griebnitzsee Campus, University of Potsdam, Germany](https://www.uni-potsdam.de/db/zeik-portal/gm/lageplan-up.php?komplex=3)

The summer school will be held at the Griebnitzsee campus of the University of Potsdam; this is about 15-20 minutes away from Berlin zoo station by train. Lectures will be held in Haus 6, Rooms S17 (Frequentist stream), S18 (Bayesian stream). Invited lectures will be held in Hoersaal H01. Campus map: [download from here](https://www.uni-potsdam.de/db/zeik-portal/gm/griebnitzsee.pdf)

## Traveling to the University of Potsdam 

Please use [bvg.de](http://www.bvg.de/en/) for planning your travel (by train or bus).

## Hotel accommodation

All the participants should have received the information about the hotels that we have booked. If not, please look at [this list](https://drive.google.com/file/d/1v32RwpDlKjHajOcxpMplNGAvt68PMo71/view?usp=sharing).

## About the summer school

The Second Summer School on Statistical Methods for Linguistics and Psychology will be held in Potsdam, Germany from **September 10-14 2018**. **Note that this summer school follows the annual international <a href="http://amor.cms.hu-berlin.de/~knoeferp/AMLaP2018/Home.html">AMLaP conference</a>, which will be held in Berlin September 6-8 2018**.

Like the first edition, this summer school will have a Bayesian and frequentist stream. Bayesian data analysis will be taught (first four days) by Michael Betancourt, who is one of the lead developers of Stan; he will be assisted by Bruno Nicenboim and Shravan Vasishth. The frequentist stream will be led by Reinhold Kliegl, Audrey Bürki, and Daniel Schad.
Both tracks will be aimed at linguists and psychologists, but are relevant for cognitive scientists working in many different areas. We will cover the necessary theoretical background for both statistical frameworks, and participants will get hands-on practice in learning to analyze real data sets.

The pace of this summer school will be intense! Participants should expect to be working hard during this one week, and to go home and review the materials after the course is over.

## How to apply

Applications will open on **15 February 2018**, and will close **1 April 2018**. Decisions will be sent out **10 April 2018**. 


<strike>To apply, please fill out this form</strike>The deadline for applications is now past. The decisions will be announced April 10 2018.

There were 235 applications, which is about 100 more than in 2017.

**Please note that decisions have been announced by email.** If you applied and didn't receive an email, please check your spam folder. If all else fails, please contact Shravan Vasishth.

## Fees

There will be a **30 Euro** fee to cover expenses for the two evenings (Tuesday and Thursday) of snacks, and for coffee and snacks during the breaks. International participants can pay on arrival in cash. Others have the option to pay electronically in advance to the following account: Landeshauptkasse Potsdam, IBAN: DE09 3005 0000 7110 4028 44, BIC: WELADEDDXXX.

Participants will pay for their own accommodation and travel, and will have to pay for their lunch themselves.

## Code of conduct

All participants will be expected to follow the [code of conduct](http://mc-stan.org/events/stancon2018/stancon-code_of_conduct.html), taken from [StanCon 2018](http://mc-stan.org/events/stancon2018/). In case a participant has any concerns, please contact any of the following people: Audrey Bürki, Shravan Vasishth, Bruno Nicenboim, Daniel Schad, or Reinhold Kliegl (see instructors' list below). 

## Curriculum

The summer school is intended for participants who have data analysis experience (especially, experience with linear mixed models is assumed), but want to work with state-of-the-art Bayesian and frequentist methods.
We will assume that participants should be comfortable with the material presented in [this article](https://github.com/vasishth/VasishthNicenboimPart1) and these [introductory lecture notes](https://github.com/vasishth/Statistics-lecture-notes-Potsdam/blob/master/IntroductoryStatistics/StatisticsNotesVasishth.pdf).

We will mainly focus on modeling repeated measures data. We will discuss hierarchical modeling in detail, using the generalized linear mixed modeling framework as a starting point. We will use [R](https://cran.r-project.org/), the lme4 package, and [Stan](mc-stan.org). Participants will be assumed to have a working knowledge of R; Stan will be taught from scratch. Everyone is expected to bring their own laptop computer.

The summer school will consist of lectures followed by hands-on exercises. 

### Hour-by-hour schedule

The schedule can be downloaded [here](https://github.com/vasishth/SMLP2018/blob/master/SMLP2018_schedule.pdf).

### Slides+code+data

Slides etc. will appear early Sept 2018.


### Bayesian stream: syllabus

Taught by [Michael Betancourt](https://betanalpha.github.io/) (10-13 Sept), [Bruno Nicenboim](http://www.ling.uni-potsdam.de/~nicenboim/), [Shravan Vasishth](http://www.ling.uni-potsdam.de/~vasishth/) (14 Sept)

This course is designed for people who want a fast entry into Bayesian data analysis and modeling using [Stan](mc-stan.org). The participants should be fairly familiar with linear modeling theory and should be experienced in fitting frequentist linear mixed models. 

- Foundations of Bayesian inference
- Bayesian computation and Markov Chain Monte Carlo
- Bayesian Modeling with Stan
- Regression modeling using Stan
- Hierarchical modeling using Stan
- Bayesian cognitive modeling

### Frequentist stream: syllabus

Taught by [Audrey Bürki](https://www.uni-potsdam.de/en/ling/staff-list/audreybuerki.html), [Reinhold Kliegl](http://www.uni-potsdam.de/en/cognitive-psychology/staff/kliegl-reinhold.html), [Daniel Schad](https://www.researchgate.net/profile/Daniel_Schad) 

This course is designed for researchers who are interested in fitting linear mixed models using the lme4 package in R, but are unsure about how to proceed with advanced topics such as model selection, contrast coding, and visualizing model fit.

- Review of linear modeling theory
- Introduction to linear mixed models
- Model selection
- Contrast coding and visualizing partial fixed effects
- Shrinkage and partial pooling
- Visualization

### Invited talks

We will have two invited talks during the summer school.

- [Sebastian Reich](http://www.math.uni-potsdam.de/~sreich/): 

    Title: An introduction to Hamiltonian Monte Carlo

    Date: 14th Sept, 2018

    Time: 2-3:30PM 

    Location: Hoersaal H02, Haus 6, Griebitzsee campus

    Abstract: Hamiltonian (or hybrid) Monte Carlo has become a highly popular methods for computational Bayesian inference. The talk will review the algorithmic foundation of Hamiltonian Monte Carlo and summarise some of the available choices for its implementation.

    Background reading: [here](https://arxiv.org/abs/1711.05337)

- [Joachim Vandekerckhove](http://web1.ss.uci.edu/~joachim/): 

    Date: 14th Sept, 2018

    Time: 4-5PM 

    Location: Hoersaal H02, Haus 6, Griebitzsee campus

   Title: Cognitive latent variable models

   Abstract: I will discuss cognitive latent variable models, a broad category of formal models that can be used to aggregate information regarding cognitive parameters across participants and tasks. Latent structures are borrowed from a vast literature in the field of psychometrics, and robust cognitive process models can be drawn from the cognitive science literature. The new modeling approach is an extension of hierarchical modeling, allows model fitting with smaller numbers of trials per task if there are multiple participants, and is ideally suited for uncovering correlations between latent task abilities as they are expressed in experimental paradigms. Multiple examples serve to illustrate the wide applicability of this hybrid approach.

   For further details on this work: [here](https://www.sciencedirect.com/science/article/pii/S0022249614000431?via%3Dihub)

## Preparation for summer school

We are assuming that participants will have a very good working knowledge of R and have considerable experience in fitting linear mixed models. Participants are expected to bring their own laptops. Wifi access will be available.

**Please make sure you have the current versions of R and RStudio installed on your computer by the time you start the summer school, and that you have the R packages rstan, brms, and rstanarm installed. To install rstan, follow the instructions [here](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started).**

## Summer school organizers and instructors

### Organisers: 
[Audrey Bürki](https://www.unige.ch/fapse/people/psycho/buerkifoschini/), 
[Bruno Nicenboim](http://www.ling.uni-potsdam.de/~nicenboim/), 
[Reinhold Kliegl](http://www.psych.uni-potsdam.de/people/kliegl/index-e.html), 
[Daniel Schad](https://www.researchgate.net/profile/Daniel_Schad), 
[Shravan Vasishth](http://www.ling.uni-potsdam.de/~vasishth/)

### Instructors:
[Michael Betancourt](https://betanalpha.github.io/), 
[Audrey Bürki](https://www.unige.ch/fapse/people/psycho/buerkifoschini/),
[Bruno Nicenboim](http://www.ling.uni-potsdam.de/~nicenboim/), 
[Reinhold Kliegl](http://www.psych.uni-potsdam.de/people/kliegl/index-e.html), 
[Daniel Schad](https://www.researchgate.net/profile/Daniel_Schad),
[Shravan Vasishth](http://www.ling.uni-potsdam.de/~vasishth/)

## Background Material

### Overview and methodological papers

- Shravan Vasishth and Bruno Nicenboim. Statistical Methods for Linguistic Research: Foundational Ideas – Part I. Language and Linguistics Compass, 10(8):349-369, 2016. [code](https://github.com/vasishth/VasishthNicenboimPart1)
- Bruno Nicenboim and Shravan Vasishth. Statistical methods for linguistic research: Foundational Ideas - Part II. *Language and Linguistics Compass*, 10:591-613, 2016. [code](https://github.com/vasishth/NicenboimVasishthPart2)
- Shravan Vasishth, Daniela Mertzen, Lena A. Jäger, and Andrew Gelman. The statistical significance filter leads to overoptimistic expectations of replicability. 2018. [pdf](https://psyarxiv.com/hbqcw)


### Papers relating to linear mixed modeling


- Hannes Matuschek, Reinhold Kliegl, Shravan Vasishth, R. Harald Baayen, and Douglas Bates. Balancing Type I Error and Power in Linear Mixed Models. Journal of Memory and Language, 94:305-315, 2017. [pdf](https://www.sciencedirect.com/science/article/pii/S0749596X17300013?via%3Dihub)
- Douglas Bates, Reinhold Kliegl, Shravan Vasishth, and Harald Baayen. Parsimonious mixed models. Unpublished manuscript, 2015. [pdf](https://arxiv.org/abs/1506.04967)
- Tanner Sorensen, Sven Hohenstein, and Shravan Vasishth.
Bayesian linear mixed models using Stan: A tutorial for
psychologists, linguists, and cognitive scientists.
*Quantitative Methods for Psychology*, 12(3):175-200, 2016.
[pdf](http://www.tqmp.org/RegularArticles/vol12-3/p175/p175.pdf),
[code and data](http://www.ling.uni-potsdam.de/~vasishth/statistics/BayesLMMs.html)
- Shravan Vasishth, Bruno Nicenboim, Mary E. Beckman, Fangfang Li, and Eun Jong Kong. Bayesian data analysis in the phonetic sciences: A tutorial introduction. Journal of Phonetics, 2018. [pdf](https://osf.io/g4zpv/)
- Daniel J. Schad, Sven Hohenstein, Shravan Vasishth, and Reinhold Kliegl. How to capitalize on a priori contrasts in linear (mixed) models: A tutorial. Unpublished manuscript, 2018. [pdf](https://arxiv.org/abs/1807.10451)

### Examples of Bayesian data analysis and Bayesian modeling from our lab

- Bruno Nicenboim, Timo B. Roettger, and Shravan Vasishth. Using meta-analysis for evidence synthesis: The case of incomplete neutralization in German. In press, Journal of Phonetics, 2018.
[pdf](https://osf.io/g5ndw/)
- Lena A. Jäger, Felix Engelmann, and Shravan Vasishth. Similarity-based interference in sentence comprehension: Literature review and Bayesian meta-analysis. Journal of Memory and Language, 94:316-339, 2017. [pdf](https://doi.org/10.1016/j.jml.2017.01.004)
- Bruno Nicenboim, Shravan Vasishth, Felix Engelmann, and Katja Suckow. Exploratory and confirmatory analyses in sentence processing: A case study of number interference in German. Cognitive Science, 2018. [pdf](https://osf.io/mmr7s/)
- Bruno Nicenboim and Shravan Vasishth. Models of retrieval in sentence comprehension: A computational evaluation using Bayesian hierarchical modeling. Journal of Memory and Language, 99:1-34, 2018. [pdf](https://www.sciencedirect.com/science/article/pii/S0749596X16301577?via%3Dihub)


### Lecture notes

These lecture notes serve as reference materials for the summer school. You are not expected to read them during the summer school, but they may help for review later on.

- [Introductory statistics notes](https://github.com/vasishth/Statistics-lecture-notes-Potsdam/blob/master/IntroductoryStatistics/StatisticsNotesVasishth.pdf).
- [Linear modeling lecture notes](https://github.com/vasishth/LM/blob/master/LinearModelingLectureNotes2016.pdf), and [Linear modeling quick review sheet](https://github.com/vasishth/LM/blob/master/LMSummarySheet.pdf); these cover frequentist linear models and linear mixed models more formally.
- [Bayesian modeling using Stan](https://github.com/vasishth/FGME_Stan_2017)

### Video lectures and tutorials on Bayes using Stan

- [Ben Goodrich's youtube lectures (Columbia)](https://www.youtube.com/playlist?list=PLSZp9QshJ8wyPCgoQR0Kw3HDNuy1FEZH9)
- [Richard McElreath's youtube lectures](https://www.youtube.com/playlist?list=PLDcUM9US4XdM9_N6XUUFrhghGJ4K25bFc)
- [Stan case studies, tutorials](http://mc-stan.org/users/documentation/index.html)


## Contact details

For any questions regarding this summer school, please contact [Shravan Vasishth](http://www.ling.uni-potsdam.de/~vasishth).

## Funding

This summer school is funded by the [DFG](dfg.de) and is part of the [SFB "Variability in Language and Its Limits"](https://www.uni-potsdam.de/sfb1287/index.html).
